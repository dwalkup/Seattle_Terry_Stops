{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling with Logistic Regression model\n",
    "\n",
    "Below is the logistic regression model for predicting arrest after a Terry Stop is taking place. The final regression model is based upon a third degree polynomial model of four features: `Officer Gender`, `Reported Time`, `weapon_present`, and `Initial Call Type`.\n",
    "\n",
    "Below are the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from category_encoders import WOEEncoder, TargetEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures as Poly\n",
    "\n",
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis\n",
    "from mlxtend.preprocessing import standardize\n",
    "\n",
    "from mlxtend.feature_extraction import RBFKernelPCA as KPCA\n",
    "from pyearth import Earth\n",
    "\n",
    "from mlxtend.plotting import plot_pca_correlation_graph\n",
    "\n",
    "# from umap import UMAP\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline components to be used. The stringify is used for the scorecard of weighted evidence that we used as a baseline. This is currently not the best model. The polynomial regression model does better. Left in the code for possible future reference if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(data):\n",
    "    if type(data) != pd.core.frame.DataFrame:\n",
    "        X = pd.DataFrame(data)\n",
    "    else:\n",
    "        X = data\n",
    "        \n",
    "    for c in X.columns.tolist():\n",
    "        X[c] = X[c].astype(str)\n",
    "#     X = X.applymap(str)\n",
    "    return X\n",
    "\n",
    "objectify = FunctionTransformer(func = stringify, check_inverse = False, validate=False)\n",
    "binner = KBinsDiscretizer(n_bins = 10, encode = 'ordinal')\n",
    "poly = Poly(degree=3)\n",
    "encoder = WOEEncoder()\n",
    "clf = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data to train the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Terry_Stops_added_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject Age Group', 'Subject ID', 'GO / SC Num', 'Terry Stop ID',\n",
       "       'Stop Resolution', 'Weapon Type', 'Officer ID', 'Officer YOB',\n",
       "       'Officer Gender', 'Officer Race', 'Subject Perceived Race',\n",
       "       'Subject Perceived Gender', 'Reported Date', 'Reported Time',\n",
       "       'Initial Call Type', 'Final Call Type', 'Call Type', 'Officer Squad',\n",
       "       'Arrest Flag', 'Frisk Flag', 'Precinct', 'Sector', 'Beat',\n",
       "       'subject_age_groups', 'stop_resolution', 'arrest_flag',\n",
       "       'weapon_present', 'officer_gender', 'officer_race', 'subject_race',\n",
       "       'subject_gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the target field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'arrest_flag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the polynomial logistic regression moxdel. The performance of the model is determined using cross validation and uses area unbder the curve (AUC) as its metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8597557865754016 +/- 0.007328641075193442\n"
     ]
    }
   ],
   "source": [
    "# excluded_cols = ['arrest_flag', 'Arrest Flag', 'stop_resolution', 'Stop Resolution', 'Subject ID']\n",
    "\n",
    "# used_cols = [c for c in df.columns if (c not in [target, 'stop_resolution'] and '_' in c)]\n",
    "# used_cols = [c for c in df.columns if c not in excluded_cols]\n",
    "\n",
    "used_cols = ['Officer Gender', 'Reported Time', 'weapon_present', 'Initial Call Type']\n",
    "X = df[used_cols]\n",
    "y = df[target]\n",
    "\n",
    "scorecard = make_pipeline(objectify, encoder, poly, clf)\n",
    "\n",
    "scores = cross_val_score(scorecard, X.values, y.values, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the cross validated scores of the different logistic fregression models:\n",
    "\n",
    "* scorecard, no poly = 0.7316332047925206 +/- 0.016245739477284915\n",
    "* 2 degrees = 0.8392500438013089 +/- 0.019636147953002545\n",
    "* 3 degrees = 0.8597557865754016 +/- 0.007328641075193442\n",
    "* 4 degrees = 0.8726112180444696 +/- 0.01681182446652548\n",
    "\n",
    "The third degree polynomial model seems to be best (has lowest standard deviation), and is hence the most stable of the models. The third degree polynomial model is using 35 features overall as can be seen below. It is unclear what the various features are, and to determine that we will develop a decision tree to figure out which interactions are the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>0.231792</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-2.229887</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.004926</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>0.053728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>-0.119807</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.020071</td>\n",
       "      <td>1.152564</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.193086</td>\n",
       "      <td>-11.087886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>0.432463</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-2.229887</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.009191</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>0.187024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080881</td>\n",
       "      <td>-0.007262</td>\n",
       "      <td>-0.417043</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.037447</td>\n",
       "      <td>2.150379</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.193086</td>\n",
       "      <td>-11.087886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>-0.260684</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-2.229887</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>0.067956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017715</td>\n",
       "      <td>-0.002639</td>\n",
       "      <td>-0.151535</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.022573</td>\n",
       "      <td>-1.296225</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.193086</td>\n",
       "      <td>-11.087886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>-0.340727</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-2.229887</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>0.116095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039557</td>\n",
       "      <td>-0.004508</td>\n",
       "      <td>-0.258878</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>-0.029504</td>\n",
       "      <td>-1.694229</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.193086</td>\n",
       "      <td>-11.087886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>-0.203526</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-2.229887</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008431</td>\n",
       "      <td>-0.001609</td>\n",
       "      <td>-0.092368</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.017623</td>\n",
       "      <td>-1.012010</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.193086</td>\n",
       "      <td>-11.087886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>0.085189</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>0.553724</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.011768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>-0.011906</td>\n",
       "      <td>0.169778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-2.229887</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.047392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.193086</td>\n",
       "      <td>-11.087886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>2.224223</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>0.842052</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.047272</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.017896</td>\n",
       "      <td>4.947166</td>\n",
       "      <td>...</td>\n",
       "      <td>11.003599</td>\n",
       "      <td>-0.192106</td>\n",
       "      <td>4.165771</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>-0.072728</td>\n",
       "      <td>1.577089</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>-0.027534</td>\n",
       "      <td>0.597058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-0.088313</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.000689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39397 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6   \\\n",
       "0      1.0 -0.021253  0.231792 -0.038832 -2.229887  0.000452 -0.004926   \n",
       "1      1.0 -0.021253  0.432463 -0.038832 -2.229887  0.000452 -0.009191   \n",
       "2      1.0 -0.021253 -0.260684 -0.038832 -2.229887  0.000452  0.005540   \n",
       "3      1.0 -0.021253 -0.340727 -0.038832 -2.229887  0.000452  0.007242   \n",
       "4      1.0 -0.021253 -0.203526 -0.038832 -2.229887  0.000452  0.004326   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "39392  1.0 -0.021253  0.000000 -0.038832  0.085189  0.000452 -0.000000   \n",
       "39393  1.0 -0.021253  0.000000 -0.038832  0.553724  0.000452 -0.000000   \n",
       "39394  1.0 -0.021253  0.000000 -0.038832 -2.229887  0.000452 -0.000000   \n",
       "39395  1.0 -0.021253  2.224223 -0.038832  0.842052  0.000452 -0.047272   \n",
       "39396  1.0 -0.021253  0.000000 -0.038832 -0.088313  0.000452 -0.000000   \n",
       "\n",
       "             7         8         9   ...         25        26        27  \\\n",
       "0      0.000825  0.047392  0.053728  ...   0.012454 -0.002086 -0.119807   \n",
       "1      0.000825  0.047392  0.187024  ...   0.080881 -0.007262 -0.417043   \n",
       "2      0.000825  0.047392  0.067956  ...  -0.017715 -0.002639 -0.151535   \n",
       "3      0.000825  0.047392  0.116095  ...  -0.039557 -0.004508 -0.258878   \n",
       "4      0.000825  0.047392  0.041423  ...  -0.008431 -0.001609 -0.092368   \n",
       "...         ...       ...       ...  ...        ...       ...       ...   \n",
       "39392  0.000825 -0.001811  0.000000  ...   0.000000 -0.000000  0.000000   \n",
       "39393  0.000825 -0.011768  0.000000  ...   0.000000 -0.000000  0.000000   \n",
       "39394  0.000825  0.047392  0.000000  ...   0.000000 -0.000000 -0.000000   \n",
       "39395  0.000825 -0.017896  4.947166  ...  11.003599 -0.192106  4.165771   \n",
       "39396  0.000825  0.001877  0.000000  ...   0.000000 -0.000000 -0.000000   \n",
       "\n",
       "             28        29        30        31        32        33         34  \n",
       "0      0.000350  0.020071  1.152564 -0.000059 -0.003362 -0.193086 -11.087886  \n",
       "1      0.000652  0.037447  2.150379 -0.000059 -0.003362 -0.193086 -11.087886  \n",
       "2     -0.000393 -0.022573 -1.296225 -0.000059 -0.003362 -0.193086 -11.087886  \n",
       "3     -0.000514 -0.029504 -1.694229 -0.000059 -0.003362 -0.193086 -11.087886  \n",
       "4     -0.000307 -0.017623 -1.012010 -0.000059 -0.003362 -0.193086 -11.087886  \n",
       "...         ...       ...       ...       ...       ...       ...        ...  \n",
       "39392  0.000000 -0.000000  0.000000 -0.000059  0.000128 -0.000282   0.000618  \n",
       "39393  0.000000 -0.000000  0.000000 -0.000059  0.000835 -0.011906   0.169778  \n",
       "39394  0.000000  0.000000  0.000000 -0.000059 -0.003362 -0.193086 -11.087886  \n",
       "39395  0.003354 -0.072728  1.577089 -0.000059  0.001270 -0.027534   0.597058  \n",
       "39396  0.000000  0.000000  0.000000 -0.000059 -0.000133 -0.000303  -0.000689  \n",
       "\n",
       "[39397 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Pipeline(scorecard.steps[:-1]).fit_transform(X.values, y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the index to the column numbers. Note this is **without** the interaction terms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Officer Gender\n",
      "1 : Reported Time\n",
      "2 : weapon_present\n",
      "3 : Initial Call Type\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(used_cols):\n",
    "    print(i, \":\", col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature is `Reported Time`. Note that this is without considering the interactions. That the `Reported Time` is such an important featureis confirmed in the decision tree model (see tree notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00050761  0.0142132   0.0001269  -0.00444162]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, \n",
    "                                                    test_size=.20, random_state=42, \n",
    "                                                    stratify=y.values)\n",
    "\n",
    "scorecard.fit(X_train, y_train)\n",
    "imp_vals, _ = feature_importance_permutation(\n",
    "    predict_method=scorecard.predict, \n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    metric='accuracy',\n",
    "    num_rounds=1,\n",
    "    seed=1)\n",
    "\n",
    "print(imp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(imp_vals)[::-1]\n",
    "plt.figure()\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.ylim([0, 0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
